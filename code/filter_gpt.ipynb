{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from itertools import islice\n",
    "from typing import Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from chatgpt import count_tokens\n",
    "from hashing import short_hash\n",
    "from prompt_1 import generate_prompt_1, classify_validation_set_1\n",
    "from prompt_2 import classify_validation_set_2, generate_prompt_2\n",
    "\n",
    "DEV_FILE_PATH = \"dev_off.csv\"\n",
    "NUM_PROMPT_EXAMPLES = 20\n",
    "NUM_CLASSIFICATION_EXAMPLES = 30\n",
    "\n",
    "\n",
    "def load_dataset(file_path: str) -> List[Dict]:\n",
    "    print(f\"Loading data from {file_path}\")\n",
    "    with open(file_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "    print(f\"Loaded {len(rows)} rows\")\n",
    "\n",
    "    for row in rows:\n",
    "        row['label'] = row['Annotation'] == 't'\n",
    "        row['hash'] = short_hash(row['sentence'])\n",
    "    print(f\"Hashed {len(rows)} rows\")\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def get_data_folds(data: List[Dict]):\n",
    "    print(f\"Splitting data into folds\")\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    positive_examples = [row for row in data if row['label'] == True]\n",
    "    negative_examples = [row for row in data if row['label'] == False]\n",
    "\n",
    "    num_folds = len(positive_examples) // NUM_PROMPT_EXAMPLES\n",
    "    for fold_i in range(num_folds):\n",
    "        fold_start = fold_i * NUM_PROMPT_EXAMPLES\n",
    "        fold_end = (fold_i + 1) * NUM_PROMPT_EXAMPLES\n",
    "\n",
    "        prompt_tuning_positive = positive_examples[fold_start:fold_end]\n",
    "        other_positive = positive_examples[:fold_start] + positive_examples[fold_end:]\n",
    "\n",
    "        prompt_tuning_negative = negative_examples[fold_start:fold_end]\n",
    "        other_negative = negative_examples[:fold_start] + negative_examples[fold_end:]\n",
    "\n",
    "        validation_set = other_positive + other_negative\n",
    "        random.shuffle(validation_set)\n",
    "\n",
    "        yield {\n",
    "            \"positives\": prompt_tuning_positive,\n",
    "            \"negatives\": prompt_tuning_negative,\n",
    "            \"validation\": validation_set\n",
    "        }\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1 = \"I was so certain that I saw you .\"\n",
    "s2 = \"I was so happy that I was freed .\"\n",
    "s3 = \"I was so happy that I cried .\"\n",
    "s4 = \"I was certain I saw you .\"\n",
    "s5 = \"I was happy I was freed .\"\n",
    "s6 = \"A further limit on the playing ability of working class teams was that working class players had to be careful how hard they played .\"\n",
    "s7 = \"The Wobblies were careful that the strike demands reflected only the immediate needs of the workers , rather than long range goals of the IWW .\"\n",
    "\n",
    "ss = [s1, s2, s3, s4, s5, s6, s7]\n",
    "\n",
    "# Load the pre-trained language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for s in ss:\n",
    "    # Process the sentence with spaCy\n",
    "    doc = nlp(s)\n",
    "    # Visualize the dependency parse tree\n",
    "    displacy.render(doc, style=\"dep\")\n",
    "\n",
    "doc = nlp(s1)\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}, Head: {token.idx}, Dep: {token.dep_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dev_off.csv\n",
      "Loaded 500 rows\n",
      "Hashed 500 rows\n",
      "Prompt 1\n",
      "Splitting data into folds\n",
      "Generating prompt 1\n",
      "No examples classified, rotating validation set\n",
      "Generating prompt 1\n",
      "430/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False          2     19\n",
      "True           1      8\n",
      "Generating prompt 1\n",
      "400/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         12     31\n",
      "True           2     15\n",
      "Generating prompt 1\n",
      "370/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         25     41\n",
      "True           5     19\n",
      "Generating prompt 1\n",
      "340/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         27     62\n",
      "True           5     26\n",
      "Generating prompt 1\n",
      "310/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         30     80\n",
      "True           8     32\n",
      "Generating prompt 1\n",
      "280/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         36     97\n",
      "True           9     38\n",
      "Generating prompt 1\n",
      "No examples classified, rotating validation set\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         36     97\n",
      "True           9     38\n",
      "Generating prompt 1\n",
      "250/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         40    116\n",
      "True          10     44\n",
      "Generating prompt 1\n",
      "220/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         44    135\n",
      "True          11     50\n",
      "Generating prompt 1\n",
      "190/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         48    151\n",
      "True          12     59\n",
      "Generating prompt 1\n",
      "160/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         51    170\n",
      "True          13     66\n",
      "Generating prompt 1\n",
      "130/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         60    183\n",
      "True          16     71\n",
      "Generating prompt 1\n",
      "100/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         71    197\n",
      "True          18     74\n",
      "Generating prompt 1\n",
      "70/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         76    213\n",
      "True          18     83\n",
      "Generating prompt 1\n",
      "40/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         84    228\n",
      "True          20     88\n",
      "Generating prompt 1\n",
      "10/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         92    239\n",
      "True          25     94\n",
      "Generating prompt 1\n",
      "0/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         92    242\n",
      "True          27     99\n",
      "(3.4444444444444446, 0.003704124068972554)\n",
      "\n",
      "\n",
      "Prompt 2\n",
      "Generating prompt 1\n",
      "430/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         16      2\n",
      "True          10      2\n",
      "Generating prompt 1\n",
      "Getting model response for prompt: The task is to classify whether the sentences are instances of the caused motion construction as fir...\n",
      "400/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         39      4\n",
      "True          14      3\n",
      "Generating prompt 1\n",
      "Getting model response for prompt: The task is to classify whether the sentences are instances of the caused motion construction as fir...\n",
      "370/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         57      7\n",
      "True          20      6\n",
      "Generating prompt 1\n",
      "Getting model response for prompt: The task is to classify whether the sentences are instances of the caused motion construction as fir...\n",
      "340/460 examples remaining\n",
      "Predicted  False  True \n",
      "Actual                 \n",
      "False         79      9\n",
      "True          25      7\n",
      "Generating prompt 1\n",
      "Getting model response for prompt: The task is to classify whether the sentences are instances of the caused motion construction as fir...\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(DEV_FILE_PATH)\n",
    "folds = get_data_folds(data)\n",
    "\n",
    "prompt_nums_to_functions = {1: (generate_prompt_1, classify_validation_set_1), 2: (generate_prompt_2, classify_validation_set_2)}\n",
    "\n",
    "def get_cost_for_prompt(prompt_num):\n",
    "\n",
    "    for fold in folds:\n",
    "        validation_set = list(fold[\"validation\"])\n",
    "        classified_set = []\n",
    "        classified_hashes = set()\n",
    "        gpt_cost = 0\n",
    "        while len(validation_set) > 0:\n",
    "            chunk = validation_set[:NUM_CLASSIFICATION_EXAMPLES]\n",
    "            initial_prompt = prompt_nums_to_functions[prompt_num][0](fold[\"positives\"], fold[\"negatives\"], chunk)\n",
    "            classified_samples, gpt_cost_chunk = prompt_nums_to_functions[prompt_num][1](initial_prompt, chunk)\n",
    "            gpt_cost += gpt_cost_chunk\n",
    "            if len(classified_samples) == 0:\n",
    "                print(\"No examples classified, rotating validation set\")\n",
    "                validation_set = validation_set[1:] + [validation_set[0]]\n",
    "            else:\n",
    "                # Remove classified examples from validation set\n",
    "                classified_set += classified_samples\n",
    "                classified_hashes = set([row['hash'] for row in classified_set])\n",
    "                validation_set = [row for row in validation_set if row['hash'] not in classified_hashes]\n",
    "                print(f\"{len(validation_set)}/{len(fold['validation'])} examples remaining\")\n",
    "\n",
    "            if len(classified_set) > 0:\n",
    "                # Get a confusion matrix for the fold (compare \"label\" and \"prediction\" columns)\n",
    "                df = pd.DataFrame(classified_set)\n",
    "                confusion_matrix = pd.crosstab(df['label'], df['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "                print(confusion_matrix)\n",
    "                tp = confusion_matrix[True][True]\n",
    "                tn = confusion_matrix[False][False]\n",
    "                fp = confusion_matrix[True][False]\n",
    "                fn = confusion_matrix[False][True]\n",
    "                human_cost_multiplier = (tp+fp)/tp\n",
    "                fixed_gpt_cost = (tp+tn+fp+fn) / tp / tp * gpt_cost\n",
    "\n",
    "        return (human_cost_multiplier, fixed_gpt_cost)\n",
    "            \n",
    "prompt_costs_dict = {}\n",
    "for prompt_num in [1,2]:\n",
    "    print(f\"Prompt {prompt_num}\")\n",
    "    prompt_costs_dict[prompt_num] = get_cost_for_prompt(prompt_num)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameters for the first line\n",
    "a1 = 2\n",
    "b1 = 3\n",
    "\n",
    "# Define the parameters for the second line\n",
    "a2 = -1\n",
    "b2 = 5\n",
    "\n",
    "# Generate x values\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Calculate y values for the first line\n",
    "y1 = prompt_costs_dict[1][0] * x + prompt_costs_dict[1][1]\n",
    "\n",
    "# Calculate y values for the second line\n",
    "y2 = prompt_costs_dict[2][0] * x + prompt_costs_dict[2][1]\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(x, y1, label='prompt 1')\n",
    "plt.plot(x, y2, label='prompt 2')\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel('human cost per annotation')\n",
    "plt.ylabel('total cost per true positive')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
